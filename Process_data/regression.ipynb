{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b487067d",
   "metadata": {},
   "source": [
    "# Aufgabe 12.3: Regressionsmodell für Endgewicht\n",
    "\n",
    "- **Abgabeformalien:** Fügen sie ein Kapitel in ihrer Dokumentation hinzu, in dem Sie die Ergebnisse der Regression dokumentieren und geben Sie die Datei `reg_<Matrikelnummer1-Matrikelnummer2-Matrikelnummer3>.csv` mit ab\n",
    "- Erstellen Sie ein Lineares Regressionsmodell zur Vorhersage des Endgewichts anhand aller sinnvollen Daten\n",
    "- Erstellen Sie für Ihren Report eine Tabelle, welche die genuzten Spalten (X) für die Vorhersage (y) enthält und den MSE-Wert für die jeweiligen Spalten\n",
    "  \n",
    "| Genutzte Spalten                            | Modell-Typ | MSE-Wert (Training)  | MSE-Wert (Test) |\n",
    "|---------------------------------------------|------------|----------------------|-----------------|\n",
    "| [Vibration_index_blue]                      | Linear     | 0.5                  | 0.6             |\n",
    "| [Vibration_index_blue, Vibration_index_blue]| Logistic   | 0.7                  | 0.8             |\n",
    "| Spalte 1, Spalte 2                          | SVM        | 0.9                  | 1.0             |\n",
    "\n",
    "- Schreiben Sie die Formel für das beste Lineare Regressionsmodell auf in der Form y=mx+b incl. der Parameter\n",
    "- Machen Sie eine Prognose für das folgende Datenset X.csv mit Ihrem besten Modell\n",
    "- Als Orientierung kann folgendes Notebook dienen docs/8_Regression_Python.ipynb, welches auch im nächsten Abschnitt vorgestellt wird\n",
    "- Speichern Sie die Prognose in einer CSV-Datei `reg_<Matrikelnummer1-Matrikelnummer2-Matrikelnummer3>.csv` und dokumentieren Sie Ihre Ergebnisse in der Markdown-Datei\n",
    "\n",
    "---\n",
    "\n",
    "## Vorbereiten der Daten\n",
    "Als erster lesen wir die Daten aus der Datenbank aus und bereiten sie für die Regression vor. Wir nutzen dafür die Pandas-Bibliothek, um die Daten in einen `Dataframe` zu laden und zu verarbeiten.\n",
    "\n",
    "Dadurch dass die Daten schon gut greinigt im `mqtt_data.json` vorliegen, kann sich viel preprocessing erspart bleiben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf1fd17",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     31\u001b[39m df_dispencer_green = pd.DataFrame([\n\u001b[32m     32\u001b[39m     {\n\u001b[32m     33\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbottle\u001b[39m\u001b[33m\"\u001b[39m: entry[\u001b[33m\"\u001b[39m\u001b[33mbottle\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m dispencer_green_entries.values()\n\u001b[32m     37\u001b[39m ])\n\u001b[32m     39\u001b[39m df_dispencer_blue = pd.DataFrame([\n\u001b[32m     40\u001b[39m     {\n\u001b[32m     41\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbottle\u001b[39m\u001b[33m\"\u001b[39m: entry[\u001b[33m\"\u001b[39m\u001b[33mbottle\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m dispencer_blue_entries.values()\n\u001b[32m     45\u001b[39m ])\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m dispencer_red = \u001b[43mdispencer_red_entries\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbottle\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfill_level_grams\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.rename(columns={\u001b[33m'\u001b[39m\u001b[33mfill_level_grams\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mfill_level_red\u001b[39m\u001b[33m'\u001b[39m})\n\u001b[32m     49\u001b[39m dispencer_green = dispencer_green_entries[[\u001b[33m'\u001b[39m\u001b[33mbottle\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfill_level_grams\u001b[39m\u001b[33m'\u001b[39m]].rename(columns={\u001b[33m'\u001b[39m\u001b[33mfill_level_grams\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mfill_level_green\u001b[39m\u001b[33m'\u001b[39m})\n\u001b[32m     50\u001b[39m dispencer_blue = dispencer_blue_entries[[\u001b[33m'\u001b[39m\u001b[33mbottle\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfill_level_grams\u001b[39m\u001b[33m'\u001b[39m]].rename(columns={\u001b[33m'\u001b[39m\u001b[33mfill_level_grams\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mfill_level_blue\u001b[39m\u001b[33m'\u001b[39m})\n",
      "\u001b[31mTypeError\u001b[39m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "with open(\"../mqtt_data.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# --- Final Weight DataFrame ---\n",
    "final_weight_entries = data.get(\"final_weight\", {})\n",
    "dispencer_red_entries = data.get(\"dispencer_red\", {})\n",
    "dispencer_green_entries = data.get(\"dispencer_green\", {})\n",
    "dispencer_blue_entries = data.get(\"dispencer_blue\", {})\n",
    "\n",
    "df_final_weight = pd.DataFrame([\n",
    "    {\n",
    "        \"bottle\": entry[\"bottle\"],\n",
    "        \"time\": pd.to_datetime(entry[\"time\"], unit=\"s\"),\n",
    "        \"final_weight\": entry[\"final_weight\"],\n",
    "        \"fill_level_red\": None,\n",
    "        \"fill_level_green\": None,\n",
    "        \"fill_level_blue\": None\n",
    "    }\n",
    "    for entry in final_weight_entries.values()\n",
    "])\n",
    "\n",
    "dispencer_red_entries = data.get(\"dispenser_blue\",{})\n",
    "df_dispenser_red = pd.DataFrame([\n",
    "    {\n",
    "        \"bottle\": entry[\"bottle\"],\n",
    "        \"fill_level_red\": entry[\"fill_level_grams\"]\n",
    "    }\n",
    "    for entry in dispencer_red_entries.values()\n",
    "])\n",
    "\n",
    "dispencer_green_entries = data.get(\"dispenser_green\",{})\n",
    "df_dispenser_green = pd.DataFrame([\n",
    "    {\n",
    "        \"bottle\": entry[\"bottle\"],\n",
    "        \"fill_level_green\": entry[\"fill_level_grams\"]\n",
    "    }\n",
    "    for entry in dispencer_green_entries.values()\n",
    "])   \n",
    "\n",
    "dispencer_blue_entries = data.get(\"dispenser_blue\",{})\n",
    "df_dispenser_blue = pd.DataFrame([\n",
    "    {\n",
    "        \"bottle\": entry[\"bottle\"]\n",
    "        \"fill_level_blue\": entry[\"fill_level_grams\"]\n",
    "    }\n",
    "    for entry in dispencer_blue_entries.values()\n",
    "])\n",
    "\n",
    "df_regression = final_weight_entries.copy()\n",
    "df_regression = pd.merge(df_regression, df_dispenser_red, on='bottle', how='left')\n",
    "df_regression = pd.merge(df_regression, df_dispenser_green, on='bottle', how='left')\n",
    "df_regression = pd.merge(df_regression, df_dispenser_blue, on='bottle', how='left')\n",
    "\n",
    "print(df_regression)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36914baf",
   "metadata": {},
   "source": [
    "## Trainings- und Testdaten\n",
    "\n",
    "Nun da die Daten sich in sauber in einem Dataframe befinden, kann das Trainieren des Modells beginnen. Dazu werden die Daten in Trainings- und Testdaten unterteilt. Dies ist wichtig, um das Modell auf neuen, unbekannten Daten zu testen und zu validieren.\n",
    "Die Unterteilung erfolgt mittels k-Fold Cross-Validation, `sk-learn` bietet dafür schon eine Funktion an.\n",
    "Dies ermöglicht eine bessere Generalisierung des Modells.\n",
    "\n",
    "Die zwei Modelle die gewählt wurde sind `LinearRegression` und `SVR` (Support Vector Regression). Diese Modelle sind gut geeignet, um die Beziehung zwischen den Eingangsvariablen und dem Endgewicht zu modellieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6827aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Genutzte Spalten Modell-Typ  MSE-Wert (Training)  MSE-Wert (Test)\n",
      "0   [final_weight]     Linear               0.0000           0.0000\n",
      "1   [final_weight]        SVM               0.0254           0.0267\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def evaluate_model(model, X, y, k=5):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    mse_train, mse_test = [], []\n",
    "\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        mse_train.append(mean_squared_error(y_train, y_train_pred))\n",
    "        mse_test.append(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "    return np.mean(mse_train), np.mean(mse_test)\n",
    "\n",
    "# Features & Ziel definieren\n",
    "X = df_final_weight[['final_weight']]  # z.B. auch mehr Spalten möglich\n",
    "y = df_final_weight['final_weight']\n",
    "\n",
    "# Ergebnis-DataFrame vorbereiten\n",
    "df_predictions = pd.DataFrame(columns=[\n",
    "    \"Genutzte Spalten\",\n",
    "    \"Modell-Typ\",\n",
    "    \"MSE-Wert (Training)\",\n",
    "    \"MSE-Wert (Test)\"\n",
    "])\n",
    "\n",
    "# Liste der Modelle\n",
    "models = [\n",
    "    (\"Linear\", LinearRegression()),\n",
    "    (\"SVM\", SVR())\n",
    "]\n",
    "\n",
    "# Evaluation für jedes Modell durchführen und eintragen\n",
    "for model_name, model in models:\n",
    "    mse_train, mse_test = evaluate_model(model, X, y, k=9)\n",
    "\n",
    "    df_predictions.loc[len(df_predictions)] = [\n",
    "        list(X.columns),  # Genutzte Spalten als Liste\n",
    "        model_name,\n",
    "        round(mse_train, 4),\n",
    "        round(mse_test, 4)\n",
    "    ]\n",
    "\n",
    "print(df_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
